apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: {{ template "nfs-provisioner.fullname" . }}
  labels:
    app: {{ template "nfs-provisioner.name" . }}
    chart: {{ template "nfs-provisioner.chart" . }}
    heritage: {{ .Release.Service }}
    release: {{ .Release.Name }}
spec:
  # TODO: Investigate how/if nfs-provisioner can be scaled out beyond 1 replica
  replicas: {{ .Values.replicaCount }}
  selector:
    matchLabels:
      app: {{ template "nfs-provisioner.name" . }}
      release: {{ .Release.Name }}
  serviceName: {{ template "nfs-provisioner.fullname" . }}
  template:
    metadata:
      labels:
        app: {{ template "nfs-provisioner.name" . }}
        chart: {{ template "nfs-provisioner.chart" . }}
        heritage: {{ .Release.Service }}
        release: {{ .Release.Name }}
    spec:
      # NOTE: This is 10 seconds longer than the default nfs-provisioner --grace-period value of 90sec
      terminationGracePeriodSeconds: 100
      serviceAccountName: {{ if .Values.rbac.create }}{{ template "nfs-provisioner.fullname" . }}{{ else }}{{ .Values.rbac.serviceAccountName | quote }}{{ end }}
      {{- if .Values.imagePullSecrets }}
      imagePullSecrets:
        {{- toYaml .Values.imagePullSecrets | nindent 8 }}
      {{- end }}
      affinity:
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
          - labelSelector:
              matchExpressions:
              - key: app
                operator: In
                values:
                - {{ template "nfs-provisioner.name" . }}
            topologyKey: "kubernetes.io/hostname"

      containers:
      - name: {{ .Chart.Name }}
        command: ["/nfs-provisioner"]
        image: "{{ .Values.image.repository }}:{{ .Values.image.tag }}"
        imagePullPolicy: {{ .Values.image.pullPolicy }}
        ports:
          - name: nfs
            containerPort: 2049
            protocol: TCP
          - name: nfs-udp
            containerPort: 2049
            protocol: UDP
          - name: nlockmgr
            containerPort: 32803
            protocol: TCP
          - name: nlockmgr-udp
            containerPort: 32803
            protocol: UDP
          - name: mountd
            containerPort: 20048
            protocol: TCP
          - name: mountd-udp
            containerPort: 20048
            protocol: UDP
          - name: rquotad
            containerPort: 875
            protocol: TCP
          - name: rquotad-udp
            containerPort: 875
            protocol: UDP
          - name: rpcbind
            containerPort: 111
            protocol: TCP
          - name: rpcbind-udp
            containerPort: 111
            protocol: UDP
          - name: statd
            containerPort: 662
            protocol: TCP
          - name: statd-udp
            containerPort: 662
            protocol: UDP
          - name: metrics
            containerPort: 9587
            protocol: TCP
        lifecycle:
          postStart:
            exec:
              command: ["/bin/sh", "-c", "cp -f /tmp/ganesha/ganesha.conf /export/vfs.conf"]
          preStop:
            exec:
              command: ["/bin/sh", "-c", "rm -f /var/run/dbus/pid"]
        env:
          - name: POD_IP
            valueFrom:
              fieldRef:
                fieldPath: status.podIP
          - name: SERVICE_NAME
            value: {{ template "nfs-provisioner.fullname" . }}
          - name: POD_NAMESPACE
            valueFrom:
              fieldRef:
                fieldPath: metadata.namespace
        volumeMounts:
          - name: data
            mountPath: /export
          - name: var-run
            mountPath: /var/run/dbus
          - name: {{ template "nfs-provisioner.fullname" . }}-config
            mountPath: /tmp/ganesha
        {{- with .Values.resources }}
        resources:
          {{- toYaml . | nindent 12 }}
        {{- end }}

      - name: controller
        command: ["/usr/local/bin/python3"]
        args: ["/app/main.py"]
        image: seasonedidiot/nfs-leader:9bbb274fe17
        imagePullPolicy: Always
        lifecycle:
          postStart:
            exec:
              command: ["/usr/local/bin/python3", "/app/create_service.py"]
          preStop:
            exec:
              command: ["/usr/local/bin/python3", "/app/delete_service.py"]
        env:
        - name: POD
          valueFrom:
            fieldRef:
              fieldPath: metadata.name
        - name: NAMESPACE
          valueFrom:
            fieldRef:
              fieldPath: metadata.namespace
        resources:
          requests:
            memory: "64Mi"
            cpu: "50m"
          limits:
            memory: "128Mi"
            cpu: "100m"
        volumeMounts:
          - name: data
            mountPath: /export

      - name: logger
        command: ["/usr/bin/tail"]
        args: ["-f","/export/ganesha.log"]
        image: seasonedidiot/nfs-leader:9bbb274fe17
        imagePullPolicy: Always
        resources:
          requests:
            memory: "64Mi"
            cpu: "50m"
          limits:
            memory: "128Mi"
            cpu: "100m"
        volumeMounts:
          - name: data
            mountPath: /export

      - name: rsyncd 
        command: ["/usr/bin/rsync"]
        args: ["--daemon", "--no-detach", "-v"]
        image: seasonedidiot/nfs-leader:9bbb274fe17
        imagePullPolicy: Always
        ports:
        - name: rsyncd
          containerPort: 873
          hostPort: 873
          protocol: TCP
        lifecycle:
          postStart:
            exec:
              command: ["/bin/sh", "-c", "cp -f /tmp/rsyncd/rsyncd.conf /etc/rsyncd.conf"]
        resources:
          requests:
            memory: "64Mi"
            cpu: "50m"
          limits:
            memory: "128Mi"
            cpu: "100m"
        volumeMounts:
          - name: data
            mountPath: /export
          - name: {{ template "nfs-provisioner.fullname" . }}-rsync-config
            mountPath: /tmp/rsyncd

      - name: gmetrics
        command: ["/usr/bin/python3"]
        args: ["/ganesha_exporter"]
        image: "{{ .Values.image.repository }}:{{ .Values.image.tag }}"
        imagePullPolicy: Always
        ports:
        - containerPort: 9587
          name: metrics
          protocol: TCP
        resources: {}
        volumeMounts:
        - mountPath: /var/run/dbus
          name: var-run

      {{- with .Values.nodeSelector }}
      nodeSelector:
        {{- toYaml . | nindent 8 }}
      {{- end }}
      {{- with .Values.affinity }}
      affinity:
        {{- toYaml . | nindent 8 }}
      {{- end }}
      {{- with .Values.tolerations }}
      tolerations:
        {{- toYaml . | nindent 8 }}
      {{- end }}

      volumes:
        - name: var-run
          emptyDir: {}
        - name: {{ template "nfs-provisioner.fullname" . }}-config
          configMap:
             name: {{ template "nfs-provisioner.fullname" . }}-config
             items:
              - key: config
                path: ganesha.conf
        - name: {{ template "nfs-provisioner.fullname" . }}-rsync-config
          configMap:
             name: {{ template "nfs-provisioner.fullname" . }}-config
             items:
              - key: rsync_config
                path: rsyncd.conf
      {{- if not .Values.persistence.enabled }}
        - name: data
          emptyDir: {}
      {{- end }}

  {{- if .Values.persistence.enabled }}
  volumeClaimTemplates:
    - metadata:
        name: data
      spec:
        accessModes: [ {{ .Values.persistence.accessMode | quote }} ]
        {{- if .Values.persistence.storageClass }}
        {{- if (eq "-" .Values.persistence.storageClass) }}
        storageClassName: ""
        {{- else }}
        storageClassName: {{ .Values.persistence.storageClass | quote }}
        {{- end }}
        {{- end }}
        resources:
          requests:
            storage: {{ .Values.persistence.size | quote }}
  {{- end }}
